# NYC Taxi Trip Duration Prediction - 2023 ğŸš–ğŸ“Š

<details>
<summary>ğŸ“‘ Table of Contents</summary>

1. [About the Project](#about-the-project)
2. [Dataset Description](#dataset-description)
3. [Feature Engineering and Data Pre-processing](#feature-engineering-and-data-pre-processing)
4. [Model Implementation](#model-implementation)
5. [Model Evaluation and Results](#model-evaluation-and-results)
6. [Conclusion](#conclusion)
7. [Libraries Used](#libraries-used)
8. [Contact](#contact)

</details>

## ğŸš€ About the Project

Welcome to the NYC Taxi Trip Duration Prediction project! ğŸ—½ğŸš• In collaboration with the NYC Taxi and Limousine Commission, we're diving into a thrilling journey of predicting taxi trip durations. Our goal is to harness the power of data and build a top-notch regression model that accurately forecasts the time it takes for a taxi ride. ğŸ“ˆğŸ’¡

## ğŸ“Š Dataset Description

Let's talk data! ğŸ“‹ Our dataset is a treasure trove of information about taxi trips:

- **id**: Unique trip identifier
- **vendor_id**: Code for trip provider
- **pickup_datetime**: When the ride started
- **dropoff_datetime**: When the ride ended
- **passenger_count**: Number of passengers
- **pickup_longitude**, **pickup_latitude**: Where the ride began
- **dropoff_longitude**, **dropoff_latitude**: Where the ride concluded
- **store_and_fwd_flag**: Was the trip stored before sending? (Y/N)

And the target we're after:

- **trip_duration**: Duration of the trip in seconds â±ï¸

## ğŸ”§ Feature Engineering and Data Pre-processing

We're transforming raw data into gold! âœ¨ Here's what we've done:

- Extracted meaningful features from pickup/dropoff times ğŸ•’
- Tamed outliers and mapped coordinates within NYC ğŸ—ºï¸
- Crafted specialized datasets by tinkering with features ğŸ§ª
- Perfected the art of data scaling and transformation ğŸ“ˆ

## ğŸ§  Model Implementation

Now, the magic happens! ğŸª„ Our models lineup includes:

1. Linear Regression
2. Lasso & Ridge Regularization
3. Polynomial Regression
4. Light Gradient-Boosting Machine
5. Decision Trees
6. XGBoost

These models are like instruments in a symphony, each adding its own flavor to the prediction masterpiece!

## âš™ï¸ Model Evaluation and Results

Time to unveil the stars ğŸŒŸ Here are the top performers:

| Model                 | Test RMSE | Test RÂ² |
| :-------------------- | :--------: | :------: |
| Linear Regression     | 28.31 | 0.58 |
| Lasso Regression     | 28.31 | 0.58 |
| Ridge Regression     | 28.31 | 0.58 |
| Polynomial Regression | 23.41 | 0.65 |
| Decision Trees        | 18.10 | 0.73 |
| LightGBM              | 13.05 | 0.81 |
| XGBoost               | 12.68 | 0.81 |

## ğŸ‰ Conclusion

Our journey ends with valuable insights ğŸŒ† The XGBoost model steals the spotlight, revealing that distance matters most, while vendor ID isn't a showstopper. ğŸš€ Feature engineering and smart dataset iterations brought out the best in our predictions.

## ğŸ“š Libraries Used

We owe it all to these libraries:

- Pandas, NumPy for data manipulation
- Matplotlib, Seaborn, Folium for visualization
- Statsmodels, SciPy, Scikit-Learn for analysis
- ELI5 for model explanations

## ğŸ“ Contact

Got questions? Reach out: [ğŸ“§ Email](mailto:supratikghosh044@gmail.com)

Let's keep predicting and exploring the world, one taxi ride at a time! ğŸŒğŸš–ğŸ”®
